{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "covered-silicon",
   "metadata": {},
   "source": [
    "In this notebook, we embed sentences and find similarity with the **reference** sentences (ODI scales). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROOT = '../data/'\n",
    "EMBEDDINGROOT = '../data/embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# utils has several different functions we use throughout the notebook\n",
    "from utils import read_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct = 'odi' # for now, we have three options a) sustainability, b) odi, c) boredom\n",
    "\n",
    "filename = {'odi' : \"ODI/ODI\",\n",
    "           }\n",
    "\n",
    "reference = pd.read_csv(DATAROOT + \"%s.tsv\" %filename[construct], sep = \"\\t\")\n",
    "\n",
    "category = \"odi_boredom_\" # blank for sustainability, \"odi_boredom\" for odi_boredom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config()\n",
    "final_goals = config['COUNTS']\n",
    "category_shorthands = config['SHORTHANDS']\n",
    "construct_references = config['REFERENCES']\n",
    "definition = config['DEFINITIONS'][construct]\n",
    "reference_name = construct_references[construct]\n",
    "final_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embed_params is a python where you can use the following functions to embed sentences \n",
    "and find the cosine similarity between embeddings\n",
    "\"\"\"\n",
    "from embed_params import embed, find_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_embeddings = embed(reference[definition].values, embedding_type = 'sbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "random_sentences = ['i\\'m really sad about everything']\n",
    "random_embeddings = embed(random_sentences, embedding_type = 'sbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(reference_embeddings)):\n",
    "    print(reference[definition].values[i], find_similarity(random_embeddings, reference_embeddings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"review_us_master\"\n",
    "data = pd.read_csv(DATAROOT + review + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "split into sentences and create dataframe with the structure\n",
    "pro_sent_id, pro, pro_sent, company_id\n",
    "\n",
    "(this is already done and saved, so just reload the sentences)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "sents = {}\n",
    "\n",
    "sent_data = {}\n",
    "\n",
    "for text in ['pros', 'cons']:\n",
    "    sents[text] = []\n",
    "    sent_data[text] = pd.read_csv(DATAROOT + \"%s_%s_sentences.csv\" %(review, text),\n",
    "                           sep = \"\\t\")#.sample(500).reset_index()\n",
    "    sent_data[text] = sent_data[text].dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_data['pros']), len(sent_data['cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data['pros'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-binding",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## do the embedding (no need to do it again)\n",
    "# for text in ['pros', 'cons']:\n",
    "#     sent_data[text][\"%s_sent_embedded\" %text] = list(embed(sent_data[text]['%s_sent' %text],\n",
    "#                                                            embedding_type = \"sbert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed once and save\n",
    "\n",
    "embedding_type = 'sbert'\n",
    "\n",
    "# for text in ['pros', 'cons']:\n",
    "#     with open(EMBEDDINGROOT+\"/%s_%s_%s_sent_embeddings.npy\" %(filename, text, embedding_type), 'wb') as f:\n",
    "#         np.save(f, sent_data[text][\"%s_sent_embedded\" %text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "for text in ['pros', 'cons']:\n",
    "    sent_data[text][\"%s_sent_embedded\" %text] = list(np.load(EMBEDDINGROOT + \\\n",
    "                                                             'review_us_master_%s_%s_sent_embeddings.npy' %(text,\n",
    "                                                                                                          embedding_type),\n",
    "                                                            allow_pickle = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the similarity with the reference data, also already done, so no need to run this, simply load the similarity\n",
    "\"\"\"\n",
    "\n",
    "# from utils import find_similarity\n",
    "\n",
    "# # do once and save\n",
    "# for text in ['pros', 'cons']:\n",
    "#     for i in final_goals[construct]:\n",
    "#         sent_data[text]['%d_sim_1' %(i)] = find_similarity(sent_data[text][\"%s_sent_embedded\" %text].values,\n",
    "#                                                reference_embeddings[i])\n",
    "        \n",
    "# # drop embeddings and save\n",
    "# for text in ['pros', 'cons']:\n",
    "#     sent_data[text] = sent_data[text].drop(\"%s_sent_embedded\" %text, axis = 1)\n",
    "#     sent_data[text].to_csv(DATAROOT+\"intermediate/%s_%s_sent_embedded.csv\" %(construct, text),\n",
    "#                            sep = \"\\t\", index = False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load already saved similarity\n",
    "for text in ['pros', 'cons']:\n",
    "     sent_data[text] = pd.read_csv(DATAROOT+\"intermediate/%s_%s_sent_embedded.csv\" %(construct, text),\n",
    "                                   sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['%d_sim_1' %i for i in final_goals[construct]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data['pros'][cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data['cons'][cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "text = 'cons'\n",
    "\n",
    "\n",
    "print(reference[reference_name].values[i])\n",
    "\n",
    "sent_data[text] = sent_data[text].drop_duplicates('%s_sent' %(text), keep = 'first')\n",
    "sent_data[text].sort_values('%d_sim_1' %(i), ascending = False)[['%s_sent' %(text),\n",
    "                                                                      '%d_sim_1' %(i)]].values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import plot_sim_dist_odi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data['cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_sim_dist_odi\n",
    "import math\n",
    "\n",
    "ncols = math.ceil(len(final_goals[construct]) / 3)\n",
    "\n",
    "plot_sim_dist_odi(sent_data, category_shorthands, construct, reference, reference_name,\n",
    "                  nrows = 3, ncols = ncols, which_goals = final_goals[construct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sent_data['cons'].copy()\n",
    "threshold = data['3_sim_1'].quantile(0.95)\n",
    "data_ = data[data[\"3_sim_1\"] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_), len(data), len(data_)/len(data), threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average of the 95th percentile\n",
    "threshold_sum = 0\n",
    "for i in cols:\n",
    "    threshold_sum += sent_data[text][i].quantile(0.95)\n",
    "threshold_sum/len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST MANUAL VALIDATION: make a table with the top ten reviews and their sim score for each ODI and boredom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "\n",
    "for text in['pros', 'cons']:\n",
    "    sent_data[text] = sent_data[text].drop_duplicates(subset = ['%s_sent' %text], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['pros', 'cons']\n",
    "\n",
    "categories = []\n",
    "refs = []\n",
    "sents = {'pros' : [], 'cons' : []}\n",
    "sent_scores = {'pros' : [], 'cons' : []}\n",
    "\n",
    "\n",
    "\n",
    "for i in final_goals[construct]:\n",
    "    categories.extend([construct]*10)\n",
    "    refs.extend([reference[reference_name].values[i]] * 10)\n",
    "    for text in ['pros', 'cons']:\n",
    "        sents[text].extend(sent_data[text].sort_values('%d_sim_1' %(i),\n",
    "                                            ascending = False)['%s_sent' %(text)].values[0:10])\n",
    "        sent_scores[text].extend(sent_data[text].sort_values('%d_sim_1' %(i),\n",
    "                                                  ascending = False)['%d_sim_1' %(i)].values[0:10])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories), len(refs), len(sents['pros']), len(sents['cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data = pd.DataFrame({\"category\": categories,\n",
    "             \"reference text\": refs,\n",
    "             \"con\" : sents['cons'],\n",
    "             \"con score\" : sent_scores['cons'],\n",
    "             \"pro\" : sents['pros'],\n",
    "             \"pro score\" : sent_scores['pros']}\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual_data.to_csv(DATAROOT + \"intermediate/pre_manual_validation_ODI_BOREDOM_stress_top_10.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND MANUAL VALIDATION: make a table, for each sentence, with 5 sentences sampled from different threshold bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data by thresholds\n",
    "# output: threshold_dict ---> text ---> goal ---> sim ---> threshold\n",
    "\n",
    "def shortlist_by_threshold(data, threshold, simfield = '_sim_1', num = 17):\n",
    "    thresholded_data = []\n",
    "    for num in range(0, num):\n",
    "        upper_threshold = threshold + 0.05\n",
    "        lower_threshold = threshold \n",
    "        thresholded_data.append(data[(data[str(num)+simfield] < upper_threshold) & (data[str(num)+simfield] > lower_threshold)])\n",
    "    return thresholded_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_dict = {}\n",
    "\n",
    "percentiles = [0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1]\n",
    "sim1_only = [\"_sim_1\"]\n",
    "\n",
    "# initialize dict\n",
    "for text in texts:\n",
    "    percentile_dict[text] = {}\n",
    "    for percentile in percentiles:\n",
    "        percentile_dict[text][percentile] = {}\n",
    "\n",
    "for text in ['pros', 'cons']:\n",
    "    for percentile in percentiles:\n",
    "        for sim in sim1_only:\n",
    "            percentile_dict[text][percentile][sim] = shortlist_by_threshold(sent_data[text],\n",
    "                                                                             percentile, sim,\n",
    "                                                                             num = len(final_goals[construct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = 0\n",
    "to_save = {}\n",
    "# save to single dataframe with the following: company_id, text, percentile\n",
    "for text in ['pros', 'cons']:\n",
    "    to_save[text] = pd.DataFrame()\n",
    "    for percentile in percentiles:\n",
    "        try:\n",
    "            data = percentile_dict[text][percentile]['_sim_1'][goal].sample(5)\n",
    "            data = data[['company_id', text+\"_sent\", \"%d_sim_1\" %goal]]\n",
    "            data['upper bound'] = [percentile+0.05] * 5\n",
    "            data['lower bound'] = [percentile] * 5\n",
    "            to_save[text] = to_save[text].append(data)\n",
    "        except:\n",
    "            pass\n",
    "#         to_save[text].to_csv(DATAROOT + \"intermediate/manual_validation_by_threshold_%s_%s.csv\" %(text, sustainability['Goal'][goal]), \n",
    "#                              sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save['cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-volume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
