{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chinese-soccer",
   "metadata": {},
   "source": [
    "About: In this notebook, we do an analysis of companies based on the relevant ODI concerns. We do the following analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct = 'odi'\n",
    "split = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=16)\n",
    "matplotlib.rc('ytick', labelsize=16)\n",
    "#plt.rcParams[\"font.family\"] = \"lato\"\n",
    "#plt.rcParams[\"font.style\"] = \"bold\"\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"lato\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.ticklabel_format(style='sci')\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# params\n",
    "from utils import read_config\n",
    "\n",
    "config = read_config()\n",
    "\n",
    "DATAROOT = \"../data/\"\n",
    "PLOTROOT = \"../plots/ODI/\"\n",
    "\n",
    "pros_cons = ['pros', 'cons']\n",
    "\n",
    "# params\n",
    "sent_based = True\n",
    "pro_or_con = config['TEXTS'][construct]\n",
    "num_goals = len(config['COUNTS'][construct])\n",
    "THRESHOLD = config['THRESHOLDS'][construct]\n",
    "PRESET = config['PRESETS'][construct]\n",
    "primary_goal_shorthand = config['SHORTHANDS'][construct]\n",
    "final_goals = config['FINAL'][construct]\n",
    "scoring = config['SCORING'][construct]\n",
    "reference_text = config['REFERENCES'][construct]\n",
    "sim_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_goals, pro_or_con, construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data, subset_by_percentile, subset_by_percentile_or_preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(DATAROOT + \"reviews_us_master.csv\")\n",
    "\n",
    "#onek_data = sample_data(main_data, review_threshold = 100)\n",
    "onek_data = sample_data(main_data, review_threshold = 900)\n",
    "onek_data = sample_data(main_data)\n",
    "\n",
    "\n",
    "sustainability = pd.read_csv(DATAROOT + config['REFERENCE_DATAS'][construct], sep = \"\\t\")\n",
    "\n",
    "main_datas = {}\n",
    "main_datas_ = {}\n",
    "\n",
    "for text in pros_cons:\n",
    "    if sent_based:\n",
    "        embed_file = \"intermediate/%s_%s_sent_embedded.csv\" %(construct, text) # sentence-based\n",
    "    else:\n",
    "        embed_file = \"intermediate/%s_embedded_sim_review.csv\" %(text) # original full pro or con\n",
    "        \n",
    "    main_datas_[text] = pd.read_csv(DATAROOT+embed_file, sep = \"\\t\")\n",
    "    #main_datas[text] = []\n",
    "    #main_datas[text].append(subset_by_percentile_or_preset(main_datas_[text], 0.8, simfield = '_sim_1', preset = 0.20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_sents(data_90, main_data, sim = 'sim_1'):\n",
    "    subsetted_data = []\n",
    "    # for a post with a shortlisted sentence, set it's score to be the maximum scoring sentence\n",
    "    for g in range(num_goals):\n",
    "        companies = data_90[g][\"company_id\"].values\n",
    "        scores = data_90[g][\"%d_%s\" %(g, sim)].values\n",
    "        post_scores = {}\n",
    "        for n, i in enumerate(companies):\n",
    "            post_scores[i] = -1\n",
    "\n",
    "        for n, i in enumerate(companies):\n",
    "            post_scores[i] = max(post_scores[i], scores[n])\n",
    "    \n",
    "\n",
    "        post_score = pd.DataFrame(post_scores.items(), columns = [\"company_id\", \"%d_%s\" %(g, sim)])\n",
    "        subsetted_data.append(post_score.merge(main_data, on = \"company_id\"))\n",
    "    return subsetted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### run once and save\n",
    "\n",
    "\n",
    "posted_sim = {}\n",
    "\n",
    "for sim in ['_sim_1']:\n",
    "    for text in pros_cons:\n",
    "        for threshold_ in [THRESHOLD]:\n",
    "            data_90 = subset_by_percentile_or_preset(main_datas_[text], threshold_,\n",
    "                                                    simfield = sim, preset = PRESET,\n",
    "                                                    num = num_goals)\n",
    "            #data_90 = subset_by_percentile(main_datas_[text], threshold_,\n",
    "            #                                         simfield = sim)\n",
    "            if sent_based:\n",
    "                data_90 = aggregate_sents(data_90, main_data)\n",
    "            top5_by_goals = pd.DataFrame()\n",
    "            ### also save full list of companies\n",
    "            company_list = {}\n",
    "            posts = []\n",
    "            for num in range(num_goals):\n",
    "                posts.append(data_90[num]['company_id'])\n",
    "            #     print(sustainibility[reference_text][num])\n",
    "            #     print(data_90[num].groupby(\"company_name\").size().sort_values().tail(5))\n",
    "                # normalize\n",
    "                company = pd.DataFrame(data_90[num].groupby(\"company_name\").size(),\n",
    "                                       columns = ['%d reviews' %num]).reset_index()\n",
    "                \n",
    "                # if z-scores are calculated using similiarity\n",
    "                company['avg sim score'] = list(data_90[num].groupby(\"company_name\").sum()['%d_sim_1' %num].values)\n",
    "                company_total_reviews = pd.DataFrame(onek_data.groupby(\"company_name\").size(), columns = ['total']).reset_index()\n",
    "                company = company.merge(company_total_reviews, on = 'company_name')\n",
    "                company['%d reviews normalized' %(num)] = company['%d reviews' %(num)] / company['total']\n",
    "                company['avg sim score'] = company['avg sim score'] / company['total']\n",
    "                top5 = company.sort_values(['%d reviews normalized' %(num)], ascending = False)\n",
    "                top5[reference_text] = [sustainability[reference_text][num]] * len(top5)\n",
    "                top5.columns = ['company_name', 'shortlisted reviews', 'avg sim score',\n",
    "                                'total reviews', 'shortlisted prop', reference_text]\n",
    "    #             print()\n",
    "    #             print(\"normalized: \")\n",
    "    #             print(top5.head(10))\n",
    "    #             print()\n",
    "    #             print(\"------------------------------------------------------------------------------------------\")\n",
    "                top5_by_goals = top5_by_goals.append(top5, ignore_index=True)\n",
    "                company_list[sustainability[reference_text][num]] = list(top5['company_name'].values)\n",
    "    \n",
    "            posted_sim[sim] = posts\n",
    "            top5_by_goals.to_csv(DATAROOT + 'intermediate/%s%s_%0.2f_company_ranking.csv' %(text,\n",
    "                                                                                            sim,\n",
    "                                                                                            threshold_),\n",
    "                                 sep = '\\t')\n",
    "            with open(DATAROOT +'intermediate/%s%s_%0.2f_company_ranking.pickle' %(text, sim, threshold_), 'wb') as handle:\n",
    "                pickle.dump(company_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAROOT +'intermediate/%s%s_%0.2f_company_ranking.pickle' %(\"cons\",\n",
    "                                                                            sim, THRESHOLD), 'rb') as handle:\n",
    "    cons = pickle.load(handle)\n",
    "    \n",
    "with open(DATAROOT +'intermediate/%s%s_%0.2f_company_ranking.pickle' %(\"pros\",\n",
    "                                                                            sim, THRESHOLD), 'rb') as handle:\n",
    "    pros = pickle.load(handle)    \n",
    "    \n",
    "cons_table = pd.read_csv(DATAROOT + 'intermediate/%s%s_%0.2f_company_ranking.csv' %(\"cons\",\n",
    "                                                                                         sim,\n",
    "                                                                                         THRESHOLD), sep = '\\t')\n",
    "pros_table = pd.read_csv(DATAROOT + 'intermediate/%s%s_%0.2f_company_ranking.csv' %(\"pros\",\n",
    "                                                                                         sim,\n",
    "                                                                                         THRESHOLD), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_table[reference_text].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_table[pros_table[reference_text] == 'gender equality'].sort_values('shortlisted prop', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-pollution",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize = (15, 10), sharex = True, sharey = 'row')\n",
    "\n",
    "goals = list(cons.keys())\n",
    "corrs = []\n",
    "\n",
    "num = 0\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        rank1 = cons[goals[final_goals[num]]]\n",
    "        rank2 = pros[goals[final_goals[num]]]\n",
    "        #print(goal)\n",
    "        #print(rank1[:5], rank2[:5])\n",
    "        \n",
    "        \n",
    "        list1 = rank1\n",
    "        list2 = rank2\n",
    "\n",
    "        common = list(set(list1).intersection(set(list2)))\n",
    "        \n",
    "\n",
    "        plotlist1 = [list1.index(i) for i in common]\n",
    "        plotlist2 = [list2.index(i) for i in common]\n",
    "        \n",
    "        corrs.append(stats.spearmanr(plotlist1, plotlist2)[0])\n",
    "#         print(sustainability[reference_text][num])\n",
    "#         print(stats.spearmanr(plotlist1, plotlist2))\n",
    "        sns.regplot(plotlist1, plotlist2, ax = axs[i][j])\n",
    "        \n",
    "        if i == 3:\n",
    "            axs[i][j].set_xlabel(\"con rank\", fontsize = 14)\n",
    "        else:\n",
    "            axs[i][j].set_xlabel(\"\", fontsize = 14)\n",
    "            \n",
    "        if j == 0:\n",
    "            axs[i][j].set_ylabel(\"pro rank\", fontsize = 14)\n",
    "        else:\n",
    "            axs[i][j].set_ylabel(\"\", fontsize = 14)\n",
    "        \n",
    "        #axs[i][j].set_title(\"Number of reviews over time (till May 2020)\", fontsize = 10)\n",
    "        subtitle = primary_goal_shorthand[sustainability[reference_text][final_goals[num]]]\n",
    "        if len(subtitle.split(' ')) > 3:\n",
    "            midway = len(subtitle) // 2\n",
    "            subtitle = subtitle[:midway] + \"\\n-\" + subtitle[midway:] \n",
    "            \n",
    "        axs[i][j].set_title(\"%s (corr = %0.2f)\" %(subtitle, corrs[-1]), fontsize = 10)\n",
    "        #print(stats.spearmanr(rank1, rank2))\n",
    "        #print()\n",
    "        num += 1\n",
    "        if num == len(final_goals):\n",
    "            break\n",
    "    if num == len(final_goals):\n",
    "            break\n",
    "\n",
    "goals_ = [sustainability[reference_text][i] for i in final_goals]            \n",
    "            \n",
    "corr_table = pd.DataFrame({reference_text : goals_,\n",
    "                      'cor' : corrs})\n",
    "\n",
    "title = \"pros_vs_cons (Def = D%d, threshold = %0.2f, preset = %0.2f)\" %(sim_num, THRESHOLD, PRESET)\n",
    "plt.suptitle(title, fontsize = 20)\n",
    "plt.savefig(PLOTROOT + \"companies/%s.pdf\" %(title))\n",
    "#plt.tight_layout()\n",
    "\n",
    "#corr_table.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import aggregate_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = {}\n",
    "\n",
    "for text in [text]:\n",
    "    data_90 = subset_by_percentile_or_preset(main_datas_[text], THRESHOLD, preset = PRESET, num = num_goals)\n",
    "    if sent_based:\n",
    "        data_90 = aggregate_sents(data_90, main_data)              \n",
    "    company_data[text] = aggregate_area(data_90, final_goals, onek_data,\n",
    "                                      sustainability,\n",
    "                                      construct = construct,\n",
    "                                      #metric = 'pro proportion',\n",
    "                                      area_name = 'company_name',\n",
    "                                      scaled = True, scoring = scoring,\n",
    "                                      find_pcs = False,\n",
    "                                      reference_text = reference_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr_table = company_data[text][1].copy()[['company_name', '1 avg sim score', '2 avg sim score',\n",
    "                                               '3 avg sim score', '5 avg sim score', 'composite']]\n",
    "cross_corr_table.columns = ['company_name', 'Depressed mood', 'Sleep alterations', 'Fatigue / loss of energy',\n",
    "       'Feelings of worthlessness', 'composite']\n",
    "cross_corr_table.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = company_data[text][1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-dietary",
   "metadata": {},
   "source": [
    "cross_corr_vars = ['ODI',\n",
    "                   'Urban Population'] + ['Depression',\n",
    "                                          'Wealth',\n",
    "                                          'Creativity'] + ['O', 'C', 'E', 'A', 'N']\n",
    "                                                               \n",
    "                                    \n",
    "\n",
    "rows = []\n",
    "for i in range(0, len(cross_corr_vars)):\n",
    "    var1 = cross_corr_vars[i]\n",
    "    row = []\n",
    "    for j in range(0, i+1):\n",
    "        var2 = cross_corr_vars[j]\n",
    "        corr, p = stats.pearsonr(df[var1], df[var2])\n",
    "        if var1 == var2:\n",
    "            row.append(\"---\")\n",
    "            continue\n",
    "        if p < 0.005:\n",
    "            stars = \"***\"\n",
    "        elif p < 0.01:\n",
    "            stars = \"**\"\n",
    "        elif p < 0.05:\n",
    "            stars = \"*\"\n",
    "        else:\n",
    "            stars = \"\"\n",
    "        row.append(str(\"%0.3f\" %corr)+stars)\n",
    "    rows.append(row)\n",
    "    \n",
    "cross_corr = pd.DataFrame(rows, columns = cross_corr_vars)    \n",
    "cross_corr[\"var\"] = cross_corr_vars\n",
    "cross_corr = cross_corr.set_index(\"var\")\n",
    "cross_corr = cross_corr.fillna(\" \")\n",
    "cross_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_corr_table.corr().round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(DATAROOT+\"companies_stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-brooks",
   "metadata": {},
   "source": [
    "## Actual Company analysis\n",
    "\n",
    "We fix the threshold here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_data = main_data[['company_name', 'GICSSector', 'GICSSubIndustry']]\n",
    "industry_data = industry_data.drop_duplicates('company_name', keep = \"first\")\n",
    "industry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_data = industry_data.fillna('Missing')\n",
    "industry_data.groupby('GICSSector').size().sort_values().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = company_data[pro_or_con][1].merge(industry_data, on = 'company_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "submetric = 'avg sim score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = '1 %s' %submetric\n",
    "ax = table.sort_values(metric,\n",
    "                                    ascending = False).head(10)[['company_name',\n",
    "                                                                 'GICSSector']].groupby('GICSSector').size().sort_values().plot(kind = 'bar')\n",
    "ax.set_title(\"Top 10 companies for\\n%s\\n(%s)\" %(sustainability[reference_text][i], metric), fontsize = 20)\n",
    "ax.set_ylabel(\"# companies\", fontsize = 18)\n",
    "ax.set_xlabel('industry', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = '3 %s' %submetric\n",
    "ax = table.sort_values(metric, ascending = False).tail(10)[['company_name', 'GICSSector']]\\\n",
    "        .groupby('GICSSector').size().sort_values().plot(kind = 'bar')\n",
    "ax.set_title(\"Low ranked companies for\\n%s\\n(%s)\" %(sustainability[reference_text][i], metric), fontsize = 20)\n",
    "ax.set_ylabel(\"# companies\", fontsize = 18)\n",
    "ax.set_xlabel('industry', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-popularity",
   "metadata": {},
   "source": [
    "## sustainability score by sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing and take those industries which have at least 5 or more companies in our dataset\n",
    "industries = ['Consumer Discretionary', 'Information Technology',\n",
    "              'Health Care', 'Financials', 'Industrials', 'Consumer Staples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = 'GICSSector'\n",
    "industry_data = table[table[sector].isin(industries)]\n",
    "industry_data.groupby(sector).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = industry_data, x = 'composite', y = 'GICSSector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_var(data, var):\n",
    "    scaled_data = [i[0]*100 for i in list(scaler.fit_transform(data[[var]]))]\n",
    "    return scaled_data\n",
    "\n",
    "def standardize(data, var):\n",
    "    return (data[var] - data[var].mean())/data[var].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-appearance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scale composite and welfare\n",
    "industry_data['composite'] = scale_var(industry_data, 'composite')\n",
    "if construct == 'odi':\n",
    "    for col in ['physiological', 'psychological']:\n",
    "        industry_data[col] = scale_var(industry_data, col)\n",
    "# industry_data['PCA1'] = scale_var(industry_data, 'PCA1')\n",
    "# industry_data['rank-diff'] = scale_var(industry_data, 'rank-diff')\n",
    "# industry_data['PCA2'] = scale_var(industry_data, 'PCA2')\n",
    "\n",
    "# z-score and scale the others\n",
    "for goal in final_goals:\n",
    "    industry_data['%d avg sim score' %goal] = standardize(industry_data, '%d avg sim score' %goal)\n",
    "    industry_data['%d avg sim score' %goal] = scale_var(industry_data, '%d avg sim score' %goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_vars=['%d avg sim score' %i for i in final_goals]\n",
    "value_vars.extend(['composite'])\n",
    "if construct == 'odi':\n",
    "    value_vars.extend(['physiological', 'psychological'])\n",
    "industry_data_melted = pd.melt(industry_data, id_vars=['company_name', 'GICSSector'],\n",
    "                               value_vars = value_vars)\n",
    "industry_data_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = dict([(\"%d avg sim score\" %i, primary_goal_shorthand[sustainability[reference_text][i]]) for i in final_goals])\n",
    "new_names['composite'] = 'composite'\n",
    "if construct == 'odi':\n",
    "    new_names['physiological'] = 'physiological'\n",
    "    new_names['psychological'] = 'psychological'\n",
    "\n",
    "# new_names['PCA1'] = composite\n",
    "# new_names['PCA2'] = 'financial'\n",
    "# new_names['rank-diff'] = 'welfare_premium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_data_melted['variable'] = industry_data_melted['variable'].map(new_names)\n",
    "industry_data_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_data_melted['variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(font=\"Lato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['composite']#list(new_names.values())\n",
    "if split:\n",
    "    col_order.extend(['psychological', 'physiological'])\n",
    "    col_wrap = 3\n",
    "else:\n",
    "    col_wrap = 1\n",
    "#[\n",
    "#             composite, 'financial', 'welfare_premium',\n",
    "#              'health', 'education', 'gender equality', 'financial benefits',\n",
    "#        'support infrastructure', 'supportive environment'\n",
    "#            ]\n",
    "g = sns.FacetGrid(industry_data_melted, col=\"variable\", height = 3, #width = 10,\n",
    "                  col_wrap = col_wrap, sharex = False,\n",
    "                  col_order = col_order)\n",
    "g.map_dataframe(sns.boxplot, x = \"value\", y = \"GICSSector\")\n",
    "g.set_axis_labels(\"ODI Score\", \"Industry Sector\", fontsize = 18)\n",
    "# g.set_titles(col_template=\"{col_name}\", size = 18)\n",
    "g.set_titles(\"\", size = 18)\n",
    "g.tight_layout()\n",
    "g.add_legend()\n",
    "g.savefig(PLOTROOT + \"companies/sector_vs_sustainability.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (7, 3.5))\n",
    "ax = sns.boxplot(data = industry_data, x = 'composite', y = 'GICSSector', color = 'steelblue')\n",
    "ax.set_xlabel('ODI score', fontweight = 'bold', fontsize = 20)\n",
    "ax.set_ylabel('Industry Sector', fontweight = 'bold', fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTROOT + \"companies/sector_vs_sustainability.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_order = list(industry_data_melted['variable'].unique())[:-3]\n",
    "# col_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(industry_data_melted, col=\"variable\", height = 6, col_wrap = 3, sharex = False, col_order = col_order)\n",
    "# g.map_dataframe(sns.boxplot, x = \"value\", y = \"GICSSector\")\n",
    "# g.set_axis_labels(\"Score\", \"Sector\", fontsize = 18)\n",
    "# g.set_titles(col_template=\"{col_name}\", size = 18)\n",
    "# g.tight_layout()\n",
    "# g.add_legend()\n",
    "# #g.savefig(PLOTROOT + \"companies/sector_vs_sustainability_ALL.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(industry_data['composite'], label = 'composite')\n",
    "# sns.distplot(industry_data['rank-diff'], label = 'emergent')\n",
    "# sns.distplot(industry_data['2 avg sim score'], label = 'health')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do some ANCOVA --- test if the different is S(c, g) and S(c) are significant while controlling # reviews\n",
    "# from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_data[['composite', 'GICSSector']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = industry_data_melted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [industry_data.groupby('GICSSector').get_group(x)[['composite']] for x in industry_data.groupby('GICSSector').groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvalue, pvalue = stats.f_oneway(dfs[0], dfs[1], dfs[2], dfs[3], dfs[4], dfs[5])\n",
    "print(fvalue, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anova(var = 'composite'):\n",
    "    data = industry_data_melted[industry_data_melted['variable'] == var]\n",
    "    anova_lists = []\n",
    "    for industry in set(data['GICSSector'].unique()):\n",
    "        data_subset = data[data['GICSSector'] == industry]\n",
    "        anova_lists.append(list(data_subset['value'].values))\n",
    "    return f_oneway(anova_lists[0], anova_lists[1], anova_lists[2],\n",
    "         anova_lists[3], anova_lists[4], anova_lists[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.marsja.se/python-manova-made-easy-using-statsmodels/\n",
    "from statsmodels.multivariate.manova import MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-replacement",
   "metadata": {},
   "source": [
    "industry_data_manova = industry_data.copy()\n",
    "industry_data_manova.columns = ['company_name', 'health', 'education', 'gender',\n",
    "       'pay', 'infra', 'peace',\n",
    "       'composite', 'PCA1', 'PCA2', 'pca-one-rank', 'pca-two-rank',\n",
    "       'rank-diff', 'GICSSector', 'GICSSubIndustry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-member",
   "metadata": {},
   "source": [
    "maov = MANOVA.from_formula('health + education + \\\n",
    "                            gender + pay + infra + peace + composite ~ GICSSector', data = industry_data_manova) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-invitation",
   "metadata": {},
   "source": [
    "print(maov.mv_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-logic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "modified-background",
   "metadata": {},
   "source": [
    "### Repeat rating correlation analysis\n",
    "\n",
    "load main data, get aggregate rating for each company, get 2019 data and then correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = [i for i in main_data.columns if 'rating' in i]\n",
    "rating_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_data_2019_company = onek_data.groupby('company_name').mean()[rating_cols]\n",
    "onek_data_2019_company = onek_data_2019_company.reset_index()\n",
    "onek_data_2019_company.columns = ['company_name', 'rating_balance',\n",
    " 'rating_career',\n",
    " 'rating_comp',\n",
    " 'rating_culture',\n",
    " 'rating_mgmt',\n",
    " 'rating_overall']\n",
    "onek_data_2019_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onek_data_2019_company), onek_data_2019_company.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_data_2019_company = onek_data_2019_company.dropna(subset = ['rating_mgmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rating in ['rating_culture', 'rating_balance', 'rating_comp', 'rating_mgmt', 'rating_career']:\n",
    "    print(rating)\n",
    "    for num in final_goals:\n",
    "        data_ = company_data[pro_or_con][1].merge(onek_data_2019_company, on = \"company_name\")\n",
    "        print(sustainability[reference_text][num], stats.pearsonr(data_['%d %s' %(num, submetric)],\n",
    "                                                      data_[rating]))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_data_2019_company_reviews = onek_data.groupby('company_name').size().reset_index()\n",
    "onek_data_2019_company_reviews.columns = ['company_name', 'reviews']\n",
    "onek_data_2019_company = onek_data_2019_company.merge(onek_data_2019_company_reviews, on = 'company_name')\n",
    "onek_data_2019_company['total reviews (logged)'] = np.log(onek_data_2019_company['reviews'])\n",
    "onek_data_2019_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_data_2019_company['rating_avg'] = onek_data_2019_company[rating_cols].mean(axis = 1)\n",
    "onek_data_2019_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "metric = 'avg sim score'\n",
    "for rating in ['rating_culture', 'rating_balance', 'rating_comp',\n",
    "               'rating_mgmt', 'rating_career', 'rating_overall',\n",
    "              'total reviews (logged)'\n",
    "              ]:\n",
    "    #print(rating)\n",
    "    row = [rating]\n",
    "    for num in final_goals:\n",
    "        data_ = company_data[pro_or_con][1].merge(onek_data_2019_company, on = \"company_name\")\n",
    "        #print(sustainability[reference_text][num], stats.pearsonr(data_['pro proportion'],\n",
    "        #                                              data_[rating]))\n",
    "        corr, p_val = stats.pearsonr(data_[\"%d %s\" %(num, metric)], data_[rating])\n",
    "        if p_val < 0.005:\n",
    "            sig = \"***\"\n",
    "        elif p_val < 0.01:\n",
    "            sig = \"**\"\n",
    "        elif p_val < 0.05:\n",
    "            sig = \"*\"\n",
    "        else:\n",
    "            sig = ''\n",
    "        row.append('%0.2f%s'%(corr, sig))\n",
    "        #row.append(p_val)\n",
    "    #data_ = onek_data_2019_company_reviews.merge(onek_data_2019_company, on = \"company\")\n",
    "    corr, p_val = stats.pearsonr(np.log(data_['reviews']), data_[rating])\n",
    "    if p_val < 0.005:\n",
    "        sig = \"***\"\n",
    "    elif p_val < 0.01:\n",
    "        sig = \"**\"\n",
    "    elif p_val < 0.05:\n",
    "        sig = \"*\"\n",
    "    else:\n",
    "        sig = ''\n",
    "    row.append('%0.2f%s'%(corr, sig))\n",
    "#     corr, p_val = stats.pearsonr(data_['rating_avg'], data_[rating])\n",
    "#     row.append(corr)\n",
    "    table.append(row)\n",
    "    #print()   \n",
    "\n",
    "columns = ['rating']    \n",
    "columns.extend([primary_goal_shorthand[sustainability[reference_text][i]] for i in final_goals])\n",
    "columns.append('total reviews (logged)')\n",
    "#columns.append('avg rating')\n",
    "rating_correlation_table = pd.DataFrame(table, columns = columns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_correlation_table['rating'] = ['culture', 'balance', 'company', 'management', 'career', 'overall', 'total reviews (logged)']\n",
    "rating_correlation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESET, THRESHOLD, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating_correlation_table.to_csv(\"../results/rating_correlation_table_weighted.csv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize by different scoring criteria\n",
    "\n",
    "def find_rating_correlation(company_data):\n",
    "    table = []\n",
    "    metric = 'avg sim score'\n",
    "    for rating in ['rating_culture', 'rating_balance', 'rating_comp',\n",
    "               'rating_mgmt', 'rating_career', 'rating_overall',\n",
    "              'total reviews (logged)'\n",
    "              ]:\n",
    "    \n",
    "        row = [rating]\n",
    "        for num in final_goals:\n",
    "            data_ = company_data.merge(onek_data_2019_company, on = \"company_name\")\n",
    "            corr, p_val = stats.pearsonr(data_[\"%d %s\" %(num, metric)], data_[rating])\n",
    "            if p_val < 0.005:\n",
    "                sig = \"***\"\n",
    "            elif p_val < 0.01:\n",
    "                sig = \"**\"\n",
    "            elif p_val < 0.05:\n",
    "                sig = \"*\"\n",
    "            else:\n",
    "                sig = ''\n",
    "            row.append('%0.2f%s'%(corr, sig))\n",
    "        corr, p_val = stats.pearsonr(np.log(data_['reviews']), data_[rating])\n",
    "        if p_val < 0.005:\n",
    "            sig = \"***\"\n",
    "        elif p_val < 0.01:\n",
    "            sig = \"**\"\n",
    "        elif p_val < 0.05:\n",
    "            sig = \"*\"\n",
    "        else:\n",
    "            sig = ''\n",
    "        row.append('%0.2f%s'%(corr, sig))\n",
    "        table.append(row)\n",
    "\n",
    "    columns = ['rating']    \n",
    "    columns.extend([primary_goal_shorthand[sustainability[reference_text][i]] for i in final_goals])\n",
    "    columns.append('total reviews (logged)')\n",
    "    rating_correlation_table = pd.DataFrame(table, columns = columns)  \n",
    "    rating_correlation_table['rating'] = ['culture', 'balance', 'company', 'management', 'career', 'overall', 'total reviews (logged)']\n",
    "    \n",
    "    return rating_correlation_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tables = {}\n",
    "\n",
    "for scoring in ['log', 'exp', 'normal']:\n",
    "    data = aggregate_area(data_90, final_goals, onek_data,\n",
    "                                      sustainability,\n",
    "                                      #metric = 'pro proportion',\n",
    "                                      construct = construct,\n",
    "                                      area_name = 'company_name',\n",
    "                                      scaled = False, scoring = scoring,\n",
    "                                      find_pcs = False,\n",
    "                                      reference_text = reference_text)\n",
    "    rating_tables[scoring] = find_rating_correlation(data[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tables['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tables['log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tables['exp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-train",
   "metadata": {},
   "source": [
    "### correlation between overall score and other goal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainable_score_corr = company_data[pro_or_con][1].rename(new_names, axis=1)\n",
    "#ax = sustainable_score_corr.corr()['composite'].sort_values().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company_data[pro_or_con][1]), len(industry_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-shade",
   "metadata": {},
   "source": [
    "Based on the rating correlation results, we will use the \"bored\" and \"never ending dimensions\", and possibly revisist \"distracted\" later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-findings",
   "metadata": {},
   "source": [
    "## company binning by percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(DATAROOT+\"companies_stock.csv\")\n",
    "stocks = stocks.rename({'company' : 'company_name'},  axis=1)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "def plot_gm_bins(company_table, metric = '2 avg sim score', start_year = '2009', end_year = '2019'):    \n",
    "    gms = []\n",
    "    gses = []\n",
    "    for percentile in range(30, 40):\n",
    "        data = company_table.copy()\n",
    "        data = data.dropna(subset = ['stock_2009', 'stock_2019'])\n",
    "        data['total_stock_growth'] = data['stock_2019'] / data['stock_2009']\n",
    "        data['log_total_stock_growth'] = np.log(data['stock_2019'] / data['stock_2009'])\n",
    "        threshold = data[metric].quantile(percentile * 0.025)\n",
    "        percentile_companies = data[data[metric] > threshold]\n",
    "    \n",
    "        gm = stats.gmean(percentile_companies['total_stock_growth'])\n",
    "        gms.append(gm)\n",
    "        \n",
    "        #gse = stats.gstd(percentile_companies['total_stock_growth'])\n",
    "        num = gm / np.sqrt(len(percentile_companies)) *\\\n",
    "            np.std(percentile_companies['log_total_stock_growth'])\n",
    "        gse = num \n",
    "                                        \n",
    "        gses.append(gse)\n",
    "    return gms, gses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-yacht",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "goal_gms = {}\n",
    "goal_gses = {}\n",
    "for goal in final_goals:\n",
    "    #data = table_weighted[table_weighted[reference_text] == sustainability[reference_text][goal]]\n",
    "    data = company_data[pro_or_con][1]\n",
    "    data = data.merge(stocks, on = \"company_name\")\n",
    "    metric = '%d avg sim score' %goal\n",
    "    goal_gms[goal], goal_gses[goal] = plot_gm_bins(data, metric)\n",
    "\n",
    "    \n",
    "data = data.merge(onek_data_2019_company[['company_name', 'reviews']], on = 'company_name')    \n",
    "goal_gms['# Reviews'], goal_gses['# Reviews'] = plot_gm_bins(data, metric = 'reviews') \n",
    "goal_gms['ODI'], goal_gses['ODI'] = plot_gm_bins(data, metric = 'composite') \n",
    "# goal_gms['rank-diff'], goal_gses['rank-diff'] = plot_gm_bins(data, metric = 'rank-diff') \n",
    "# goal_gms['PCA2'], goal_gses['PCA2'] = plot_gm_bins(data, metric = 'PCA2') \n",
    "\n",
    "if construct == 'odi':\n",
    "    goal_gms['physiological'], goal_gses['physiological'] = plot_gm_bins(data, metric = 'physiological') \n",
    "    goal_gms['psychological'], goal_gses['psychological'] = plot_gm_bins(data, metric = 'psychological') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_gms_table = pd.DataFrame(goal_gms)\n",
    "goal_gses_table = pd.DataFrame(goal_gses)\n",
    "\n",
    "extras = ['# Reviews', 'ODI']\n",
    "if construct == 'odi':\n",
    "    extras.extend(['psychological', 'physiological'])\n",
    "\n",
    "goal_gms_table.columns = final_goals + extras\n",
    "goal_gses_table.columns = [\"{} SE\".format(i) for i in goal_gms_table.columns]\n",
    "goal_gms_table = pd.concat([goal_gms_table, goal_gses_table], axis=1)\n",
    "goal_gms_table['percentile'] = [(1-i*0.025)*100 for i in range(30, 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_gms_table['percentile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_gms_table = goal_gms_table.reindex(index = goal_gms_table.index[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-university",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (18, 5))\n",
    "factor = 0\n",
    "for goal in final_goals:\n",
    "#     ax = sns.lineplot(data = goal_gms_table, x = \"percentile\",\n",
    "#                       y = goal, label = goal_shorthand[sustainability[reference_text][goal]])\n",
    "    \n",
    "    if type(goal) != str:\n",
    "        goal_gms_table['percentile %d' %goal] = goal_gms_table['percentile'] + factor\n",
    "        #goal_gms_table['percentile %d' %goal] = [str('%0.2f' %i) for i in goal_gms_table['percentile %d' %goal]]\n",
    "        goal_gms_table.plot(x = \"percentile %d\" %goal, y = goal, yerr = \"%d SE\" %goal, capsize=4,\n",
    "                        label = primary_goal_shorthand[sustainability[reference_text][goal]], ax = ax)\n",
    "    else:\n",
    "        goal_gms_table['percentile %s' %goal] = goal_gms_table['percentile'] + factor\n",
    "        goal_gms_table.plot(x = 'percentile %s' %goal , y = goal, yerr = \"%s SE\" %goal, capsize=4,\n",
    "                        label = goal, ax = ax)\n",
    "    factor += 0.01\n",
    "    \n",
    "ax.invert_xaxis()    \n",
    "ax.set_ylabel('GM Stock Growth (2009 - 2019)', fontsize = 16)\n",
    "ax.set_xlabel('Sustainability score percentile', fontsize = 16)\n",
    "plt.legend(bbox_to_anchor=(1, 1), fontsize = 16)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(PLOTROOT + 'companies/geometric_mean_bin_plot_gender_pay_reviews_composite.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-finnish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10, 5))\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "\n",
    "factor = 0\n",
    "\n",
    "goals = ['ODI','# Reviews']\n",
    "if split:\n",
    "    goals.extend(['physiological', 'psychological'])\n",
    "\n",
    "for goal in goals:\n",
    "#     ax = sns.lineplot(data = goal_gms_table, x = \"percentile\",\n",
    "#                       y = goal, label = goal_shorthand[sustainability[reference_text][goal]])\n",
    "    \n",
    "    if type(goal) != str:\n",
    "        goal_gms_table['percentile %d' %goal] = goal_gms_table['percentile'] + factor\n",
    "        #goal_gms_table['percentile %d' %goal] = [str('%0.2f' %i) for i in goal_gms_table['percentile %d' %goal]]\n",
    "        goal_gms_table.plot(x = \"percentile %d\" %goal, y = goal, yerr = \"%d SE\" %goal, capsize=4,\n",
    "                        label = primary_goal_shorthand[sustainability[reference_text][goal]], ax = ax)\n",
    "    else:\n",
    "        goal_gms_table['percentile %s' %goal] = goal_gms_table['percentile'] + factor\n",
    "        if goal == 'composite':\n",
    "            goal_gms_table.plot(x = 'percentile %s' %goal , y = goal, yerr = \"%s SE\" %goal, capsize=4,\n",
    "                        label = \"composite score\", ax = ax)\n",
    "        elif goal == '# reviews':\n",
    "            goal_gms_table.plot(x = 'percentile %s' %goal , y = goal, yerr = \"%s SE\" %goal, capsize=4,\n",
    "                        label = goal, ax = ax, style = '.', color = 'grey', alpha = 0.5)\n",
    "        else:\n",
    "            goal_gms_table.plot(x = 'percentile %s' %goal , y = goal, yerr = \"%s SE\" %goal, capsize=4,\n",
    "                        label = goal, ax = ax)\n",
    "            \n",
    "    factor -= 0.3\n",
    "    \n",
    "ax.invert_xaxis()    \n",
    "ax.set_ylabel('GM', fontsize = 34, fontweight = 'bold')\n",
    "ax.set_xlabel('Score of top X% of companies', fontsize = 24, fontweight = 'bold')\n",
    "ax.tick_params(axis = \"x\", labelsize = 16) \n",
    "ax.set_yticklabels(ax.get_yticks(), size = 16)\n",
    "#ax.set_xticklabels(ax.get_xticks(), size = 16)\n",
    "ax.set_yticklabels(ax.get_yticks().astype(int))\n",
    "ax.set_title(\"Geometric Mean (GM) of Stock Growth of Companies\", fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(fontsize = 18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTROOT + 'companies/geometric_mean_bin_plot_reviews_composite_welfare_financial_half_finer.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_gms_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-maple",
   "metadata": {},
   "source": [
    "The following analysis doesn't make sense in the boredom / ODI context, at least not until we define what the PCs represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-registrar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-banking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
