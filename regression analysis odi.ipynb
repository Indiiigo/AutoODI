{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "partial-poultry",
   "metadata": {},
   "source": [
    "**About**: We find the association between company level indicators (ratings) and state indicators against ODI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct = 'odi'\n",
    "interact = True\n",
    "split = False # flag for splitting ODI into physio and psycho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=16)\n",
    "matplotlib.rc('ytick', labelsize=16)\n",
    "plt.rcParams[\"font.family\"] = \"lato\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "#plt.ticklabel_format(style='sci')\n",
    "\n",
    "font = {'size'   : 18}\n",
    "\n",
    "#matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "DATAROOT = \"../data/\"\n",
    "PLOTROOT = \"../plots/\"\n",
    "\n",
    "# params\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=16)\n",
    "matplotlib.rc('ytick', labelsize=16)\n",
    "plt.ticklabel_format(style='sci', axis='y')\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# params\n",
    "from utils import read_config\n",
    "\n",
    "config = read_config()\n",
    "\n",
    "DATAROOT = \"../data/\"\n",
    "PLOTROOT = \"../plots/ODI/states/\"\n",
    "\n",
    "pros_cons = ['pros', 'cons']\n",
    "\n",
    "\n",
    "# params\n",
    "sent_based = True\n",
    "text = config['TEXTS'][construct]\n",
    "num_goals = len(config['COUNTS'][construct])\n",
    "THRESHOLD = config['THRESHOLDS'][construct]\n",
    "PRESET = config['PRESETS'][construct]\n",
    "primary_goal_shorthand = config['SHORTHANDS'][construct]\n",
    "final_goals = config['FINAL'][construct]\n",
    "scoring = config['SCORING'][construct]\n",
    "reference_text = config['REFERENCES'][construct]\n",
    "num_goals = len(config['COUNTS'][construct])\n",
    "sim_num = 0\n",
    "\n",
    "metric = 'avg sim score' # or 'pro proportion' (unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_var(data, var):\n",
    "    scaled_data = [i[0]*100 for i in list(scaler.fit_transform(data[[var]]))]\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENT VARIABLE: first get stocks data\n",
    "stocks = pd.read_csv(DATAROOT + \"companies_stock.csv\")\n",
    "stocks = stocks.dropna(subset = ['stock_2009', 'stock_2019'])\n",
    "stocks['total_stock_growth'] = stocks['stock_2019'] / stocks['stock_2009']\n",
    "stocks['log_total_stock_growth'] = np.log(stocks['total_stock_growth'])\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.corr()['log_total_stock_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks['log_total_stock_growth'].plot(kind = 'hist', bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(DATAROOT + \"review_us_master.csv\")\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sustainability variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "#onek_data = sample_data(review, review_threshold = 500)\n",
    "#onek_data = sample_data(review, review_threshold = 1050)\n",
    "#onek_data = sample_data(review, 900)\n",
    "onek_data = sample_data(review)\n",
    "\n",
    "sustainability = pd.read_csv(DATAROOT + config['REFERENCE_DATAS'][construct], sep = \"\\t\")\n",
    "\n",
    "main_datas = {}\n",
    "main_datas_ = {}\n",
    "\n",
    "for text in pros_cons:\n",
    "    if sent_based:\n",
    "        embed_file = \"intermediate/%s_%s_sent_embedded.csv\" %(construct, text) # sentence-based\n",
    "    else:\n",
    "        embed_file = \"intermediate/%s_embedded_sim_review.csv\" %(text) # original full pro or con\n",
    "        \n",
    "    main_datas_[text] = pd.read_csv(DATAROOT+embed_file, sep = \"\\t\")\n",
    "    #main_datas[text] = []\n",
    "    #main_datas[text].append(subset_by_percentile_or_preset(main_datas_[text], 0.8, simfield = '_sim_1', preset = 0.20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add nokia data\n",
    "# for text in ['pros']:\n",
    "# #     if sent_based:\n",
    "# #         embed_file = \"intermediate/%s_sent_embedded.csv\" %(text) # sentence-based\n",
    "# #     else:\n",
    "# #         embed_file = \"intermediate/%s_embedded_sim_review.csv\" %(text) # original full pro or con\n",
    "#     if sent_based:\n",
    "#         embed_file = \"intermediate/nokia_data_%s_sent_embedded.csv\" %(text) # sentence-based\n",
    "#     else:\n",
    "#         embed_file = \"intermediate/%s_embedded_sim_review.csv\" %(text) # original full pro or con\n",
    "        \n",
    "#     main_datas_[text] = main_datas_[text].append(pd.read_csv(DATAROOT+embed_file, sep = \"\\t\")).reset_index()\n",
    "\n",
    "    \n",
    "# # add nokia data to onek_data and main_data\n",
    "# onek_data = onek_data.append(pd.read_csv(\"../data/nokia_data.csv\")).reset_index()\n",
    "# review = review.append(pd.read_csv(\"../data/nokia_data.csv\")).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import subset_by_percentile_or_preset, aggregate_sents\n",
    "\n",
    "\n",
    "posted_sim = {}\n",
    "\n",
    "\n",
    "for text_ in pros_cons:\n",
    "    data_90 = subset_by_percentile_or_preset(main_datas_[text_], THRESHOLD, preset = PRESET, num = num_goals)\n",
    "    if sent_based:\n",
    "        data_90 = aggregate_sents(data_90, review, num_goals = num_goals)\n",
    "        top5_by_goals = {}\n",
    "        ### also save full list of companies\n",
    "        company_list = {}\n",
    "        posts = []\n",
    "        for num in final_goals:\n",
    "            posts.append(data_90[num]['company_id'])\n",
    "            company = pd.DataFrame(data_90[num].groupby(\"company_name\").size(),\n",
    "                                       columns = ['%d reviews' %num]).reset_index()\n",
    "                \n",
    "            \n",
    "            company['avg sim score'] = list(data_90[num].groupby(\"company_name\").sum()['%d_sim_1' %num].values)\n",
    "            company_total_reviews = pd.DataFrame(onek_data.groupby(\"company_name\").size(), columns = ['total']).reset_index()\n",
    "            company = company.merge(company_total_reviews, on = 'company_name')\n",
    "            company['%d reviews normalized' %(num)] = company['%d reviews' %(num)] / company['total']\n",
    "            company['avg sim score'] = company['avg sim score'] / company['total']\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            top5 = company.sort_values(['%d reviews normalized' %(num)], ascending = False)\n",
    "            top5[reference_text] = [sustainability[reference_text][num]] * len(top5)\n",
    "            top5.columns = ['company', 'shortlisted reviews', 'avg sim score',\n",
    "                                'total reviews', 'pro proportion', reference_text]\n",
    "            top5_by_goals[num] = top5\n",
    "            company_list[sustainability[reference_text][num]] = list(top5['company'].values)\n",
    "            # find the z-score of each goal\n",
    "            #z_score = \n",
    "        # add the composite score here\n",
    "        \n",
    "        posted_sim = posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import aggregate_area\n",
    "\n",
    "company_data = {}\n",
    "\n",
    "for text_ in [text]:\n",
    "    data_90 = subset_by_percentile_or_preset(main_datas_[text], THRESHOLD, preset = PRESET, num = num_goals)\n",
    "    if sent_based:\n",
    "        data_90 = aggregate_sents(data_90, review, num_goals = num_goals)              \n",
    "    company_data[text] = aggregate_area(data_90, final_goals, onek_data,\n",
    "                                      sustainability,\n",
    "                                      #metric = 'pro proportion',\n",
    "                                      construct = construct,\n",
    "                                      area_name = 'company_name',\n",
    "                                      find_pcs = False,\n",
    "                                      reference_text = reference_text,\n",
    "                                      scaled = True, scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data[text][1].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in final_goals:\n",
    "    print(len(top5_by_goals[num]))\n",
    "    stocks = stocks.merge(top5_by_goals[num][['company', metric]], on = 'company')\n",
    "    stocks.rename({'%s' %metric : '%d %s' %(num, metric)}, axis=1, inplace=True)\n",
    "    \n",
    "stocks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_again = pd.read_csv(DATAROOT+\"companies_stock.csv\")\n",
    "stocks_again = stocks_again.rename({'company' : 'company_name'},  axis=1)\n",
    "company_stocks = company_data[text][1].copy()\n",
    "company_stocks = company_stocks.merge(stocks_again, on = \"company_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_total_reviews = pd.DataFrame(review.groupby('company_name').size()).reset_index()\n",
    "company_total_reviews.columns = ['company_name', 'total reviews']\n",
    "company_stocks = company_stocks.merge(company_total_reviews, on = 'company_name')\n",
    "company_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_stocks[['total_posts', 'total reviews']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-phenomenon",
   "metadata": {},
   "source": [
    "### actual regression\n",
    "\n",
    "as a starting point, try predicting log_total_stock_growth with total reviews, average rating and the different ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress(data, evs, dv):\n",
    "    Y = data[dv]\n",
    "    X = sm.add_constant(data[evs])\n",
    "    model = sm.OLS(Y,X)\n",
    "    results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-leather",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stepaic: https://stackoverflow.com/questions/22428625/does-statsmodels-or-another-python-package-offer-an-equivalent-to-rs-step-f\n",
    "\n",
    "import itertools\n",
    "\n",
    "def stepaic_model(train, predictorcols, target):\n",
    "\n",
    "    AICs = {}\n",
    "\n",
    "    for k in range(1,len(predictorcols)+1):\n",
    "        for variables in itertools.combinations(predictorcols, k):\n",
    "            predictors = train[list(variables)]\n",
    "            predictors = sm.add_constant(predictors)\n",
    "            res = sm.OLS(train[target], predictors).fit()\n",
    "            AICs[variables] = 2*(k+1) - 2*res.llf\n",
    "    \n",
    "    min_so_far = (list(AICs.keys())[0], AICs[list(AICs.keys())[0]])\n",
    "    for key in AICs:\n",
    "        if AICs[key] < AICs[min_so_far[0]]:\n",
    "            min_so_far = (key, AICs[key])\n",
    "        \n",
    "    return min_so_far   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stocks\n",
    "dv = 'log_total_stock_growth'\n",
    "evs = ['total_posts', \n",
    "            'rating_balance', 'rating_career', 'rating_comp', 'rating_culture', 'rating_mgmt',\n",
    "       'rating_overall']\n",
    "rating_model = regress(stocks, evs, dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-marijuana",
   "metadata": {},
   "source": [
    "now add the sustaianbaility variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['total_posts',\n",
    "            #'rating_balance', 'rating_career', 'rating_comp', 'rating_culture', 'rating_mgmt',\n",
    "       #'rating_overall'\n",
    "                   ]\n",
    "selected_columns.extend([\"%d %s\" %(i, metric) for i in final_goals])\n",
    "sustainable_model = regress(stocks, evs = selected_columns, dv = dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoutput = summary_col([sustainable_model],stars=True)\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-anthony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plots for the stock growth\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (24, 4), sharey = True)\n",
    "for n, num in enumerate(final_goals):\n",
    "    sns.scatterplot(data = stocks, y = 'log_total_stock_growth', x = '%d %s' %(num, metric), ax = ax[n])\n",
    "    corr, p = stats.pearsonr(stocks['log_total_stock_growth'], stocks['%d %s' %(num, metric)])\n",
    "    ax[n].set_title(\"%s\\n%0.2f %0.2f\" %(primary_goal_shorthand[sustainability[reference_text][num]],\n",
    "                                        corr, p), fontsize = 18)\n",
    "    if n == 0:\n",
    "        ax[n].set_ylabel(\"log_total_stock_growth\", fontsize = 18)\n",
    "    ax[n].set_xlabel(metric, fontsize = 18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: predict company ratings from sustainability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = ['%d avg sim score' %i for i in final_goals]\n",
    "evs = evs + ['total_posts']#, 'composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs = ['rating_career', 'rating_comp', 'rating_culture', 'rating_mgmt',\n",
    "       'rating_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    rating_models.append(regress(stocks, evs = evs, dv = dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = ['%d avg sim score' %i for i in final_goals]\n",
    "evs = evs + ['total_posts', 'composite']\n",
    "\n",
    "dvs = ['rating_balance',\n",
    "       'rating_career', 'rating_comp', 'rating_culture', 'rating_mgmt',\n",
    "       'rating_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the differently aggregated data\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    company_stocks[dv + '_scaled'] = scale_var(company_stocks, dv)\n",
    "    rating_models.append(regress(company_stocks, evs = evs, dv = dv + '_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with stepaic\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    stepaic_evs, _ = stepaic_model(company_stocks, evs, dv + '_scaled')\n",
    "    rating_models.append(regress(company_stocks, evs = list(stepaic_evs), dv = dv + '_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer(rating_models).render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = [\"physiological\", \"psychological\", 'total reviews']\n",
    "\n",
    "for ev in evs:\n",
    "    company_stocks[ev + '_scaled'] = scale_var(company_stocks, ev)\n",
    "    \n",
    "evs = [ev + '_scaled' for ev in evs]    \n",
    "\n",
    "dvs = ['rating_balance',\n",
    "       'rating_career', 'rating_culture', 'rating_mgmt', 'rating_comp', \n",
    "      # 'rating_overall'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the differently aggregated data\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    company_stocks[\n",
    "        dv + '_scaled'] = scale_var(company_stocks, dv)\n",
    "    rating_models.append(regress(company_stocks, evs = evs, dv = dv + '_scaled'))\n",
    "    \n",
    "# with stepaic\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    stepaic_evs, _ = stepaic_model(company_stocks, evs, dv + '_scaled')\n",
    "    rating_models.append(regress(company_stocks, evs = list(stepaic_evs), dv = dv + '_scaled'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in paper (Table 4)\n",
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer(rating_models).render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict ratings for ALL 104 companies and not just those that have stock data\n",
    "all_companies = company_data[text][1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = all_companies.merge(company_total_reviews, on = 'company_name')\n",
    "all_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = ['rating_balance',\n",
    " 'rating_career',\n",
    " 'rating_comp',\n",
    " 'rating_culture',\n",
    " 'rating_mgmt',\n",
    " 'rating_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratings\n",
    "\n",
    "onek_data_2019_company = onek_data.groupby('company_name').mean()[rating_cols]\n",
    "onek_data_2019_company = onek_data_2019_company.reset_index()\n",
    "onek_data_2019_company.columns = ['company_name', 'rating_balance',\n",
    " 'rating_career',\n",
    " 'rating_comp',\n",
    " 'rating_culture',\n",
    " 'rating_mgmt',\n",
    " 'rating_overall'\n",
    "                                 ]\n",
    "\n",
    "all_companies = all_companies.merge(onek_data_2019_company, on = 'company_name')\n",
    "len(all_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = ['composite', \n",
    "#       'physiological',\n",
    "#       'psychological',\n",
    "      'total reviews'\n",
    "      ]\n",
    "\n",
    "for ev in evs:\n",
    "    all_companies[ev + '_scaled'] = scale_var(all_companies, ev)\n",
    "    \n",
    "evs = [ev + '_scaled' for ev in evs]    \n",
    "\n",
    "dvs = ['rating_balance',\n",
    "       'rating_career', 'rating_culture', 'rating_mgmt', 'rating_comp', \n",
    "      # 'rating_overall'\n",
    "      ]\n",
    "\n",
    "# with the differently aggregated data\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    all_companies[dv + '_scaled'] = scale_var(all_companies, dv)\n",
    "    rating_models.append(regress(all_companies, evs = evs, dv = dv + '_scaled'))\n",
    "    \n",
    "# with stepaic\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    stepaic_evs, _ = stepaic_model(all_companies, evs, dv + '_scaled')\n",
    "    rating_models.append(regress(all_companies, evs = evs, dv = dv + '_scaled'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepaic_evs, dvs, evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer(rating_models).render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-girlfriend",
   "metadata": {},
   "source": [
    "### Predict ODI / boredom from the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs = ['physiological', 'psychological', 'composite']\n",
    "\n",
    "evs = ['rating_balance',\n",
    "       'rating_career', 'rating_culture', 'rating_mgmt', 'rating_comp', \n",
    "       'total reviews'\n",
    "      # 'rating_overall'\n",
    "      ]\n",
    "\n",
    "\n",
    "for ev in evs:\n",
    "    all_companies[ev + '_scaled'] = scale_var(all_companies, ev)\n",
    "    \n",
    "evs = [ev + '_scaled' for ev in evs]    \n",
    "\n",
    "\n",
    "# with the differently aggregated data\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    all_companies[dv + '_scaled'] = scale_var(all_companies, dv)\n",
    "    rating_models.append(regress(all_companies, evs = evs, dv = dv + '_scaled'))\n",
    "    \n",
    "# with stepaic\n",
    "\n",
    "rating_models = []\n",
    "for dv in dvs:\n",
    "    stepaic_evs, _ = stepaic_model(all_companies, evs, dv + '_scaled')\n",
    "    rating_models.append(regress(all_companies, evs = list(stepaic_evs), dv = dv + '_scaled'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer(rating_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer(rating_models).render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-italic",
   "metadata": {},
   "source": [
    "# state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load external data\n",
    "# load dependent variable and control variables\n",
    "states = pd.read_csv(\"../data/us_states_geo.csv\")\n",
    "states['State Abbreviation'] = states['state_code']\n",
    "states = states[['State Abbreviation', 'population_2019']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_state_data = pd.read_csv(DATAROOT + \"US_States/US_State_Control_Data_Master.csv\", sep = \"\\t\")\n",
    "mega_state_data = mega_state_data.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = pd.read_csv(DATAROOT + \"US_States/US States Solar Power.csv\")\n",
    "mega_state_data = mega_state_data.merge(solar[['State Abbreviation', 'SEIA Ranking 2017']],\n",
    "                                        on = 'State Abbreviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_class = pd.read_csv(DATAROOT + \"US_States/creative_class.csv\")\n",
    "creative_class['State'] = creative_class['State ']\n",
    "extra_spaces = list(set(creative_class['State'].values) - set(mega_state_data['State'].values))\n",
    "creative_class['State'] = [i[:-1] if i in extra_spaces else i for i in creative_class['State']]\n",
    "creative_class['State'] = [i[1:] if i == ' Massachusetts' else i for i in creative_class['State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_state_data = mega_state_data.merge(creative_class[['State', 'Creativity Index ']], on = 'State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about depression\n",
    "\n",
    "mega_state_data['H_2a_depression_num'] = [float(i[:-1]) for i in mega_state_data['H_2a_depression']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality = pd.read_csv(DATAROOT + \"US_States/personality.csv\", sep = \"\\t\")\n",
    "personality = personality.dropna(axis=1, how='all')\n",
    "personality.columns = ['State', 'Sample size', 'Extraversion', 'Agreebleness',\n",
    "                       'Conscientiousness', 'Neuroticism', 'Openness']\n",
    "\n",
    "mega_state_data = mega_state_data.merge(personality[['State', 'Extraversion', 'Agreebleness',\n",
    "                       'Conscientiousness', 'Neuroticism', 'Openness']], on = 'State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.merge(mega_state_data, on = 'State Abbreviation')\n",
    "states['population_2019_log'] = np.log(states['population_2019'])\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = []\n",
    "\n",
    "# only keep numerical variables\n",
    "\n",
    "for col in states.columns:\n",
    "    if states[col].dtype in numerics:\n",
    "        selected_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv's: 'E_2a_gdp' and 'P_3c_giniCoefficient'\n",
    "for i in ['E_2a_gdp', 'P_3c_giniCoefficient',\n",
    "          'population_2019', 'FIPS Code', 'Alt FIPS Code', \n",
    "          #'State',\n",
    "          'H_2a_depression_num',\n",
    "          'S_7b_trustGeneral' # this one has lots of NaNs\n",
    "         ]:\n",
    "    try:\n",
    "        selected_columns.remove(i)    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(i)\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import aggregate_area\n",
    "\n",
    "# def aggregate_area(data, final_goals, onek_data, sustainability,\n",
    "#                    metric = 'avg sim score',\n",
    "#                    area_name = 'company_name', scaled = False):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sustainability variables\n",
    "state_data = {}\n",
    "\n",
    "\n",
    "for text in [text]:\n",
    "    data_90 = subset_by_percentile_or_preset(main_datas_[text], THRESHOLD, preset = PRESET, num = num_goals)\n",
    "    if sent_based:\n",
    "        data_90 = aggregate_sents(data_90, review, num_goals = num_goals)              \n",
    "    state_data[text] = aggregate_area(data_90, final_goals, onek_data,\n",
    "                                      sustainability, area_name = 'state',\n",
    "                                      construct = construct,\n",
    "                                      find_pcs = False,\n",
    "                                      reference_text = reference_text,\n",
    "                                      scaled = True)\n",
    "\n",
    "state_columns = list(state_data[text][1].columns)\n",
    "state_columns[0] = \"State Abbreviation\"\n",
    "state_data[text][1].columns = state_columns\n",
    "states = states.merge(state_data[text][1], on = \"State Abbreviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = state_data[text][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[['composite', 'population_2019', \n",
    "        'Openness', 'E_2a_gdp',\n",
    "        'Creativity Index ', 'H_2a_depression_num']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "if split:\n",
    "    states[['psychological', 'physiological', 'composite', 'Openness', 'E_2a_gdp', 'H_2a_depression_num']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_total_reviews = pd.DataFrame(review.groupby('state').size()).reset_index()\n",
    "state_total_reviews.columns = ['State Abbreviation', 'total reviews']\n",
    "states = states.merge(state_total_reviews, on = 'State Abbreviation')\n",
    "states['total reviews_log'] = np.log(states['total reviews'])\n",
    "# interaction\n",
    "states['total_reviews_state_population_interaction'] = states['total reviews_log'] * states['population_2019_log']\n",
    "states = states.dropna(subset = ['P_3c_giniCoefficient', 'E_2a_gdp'])\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (24, 4), sharey = True)\n",
    "for n, num in enumerate(final_goals):\n",
    "    sns.scatterplot(data = states, y = 'E_2a_gdp', x = '%d %s' %(num, metric), ax = ax[n])\n",
    "    corr, p = stats.pearsonr(states['E_2a_gdp'], states['%d %s' %(num, metric)])\n",
    "    ax[n].set_title(\"%s\\n%0.2f %0.2f\" %(primary_goal_shorthand[sustainability[reference_text][num]], corr, p), fontsize = 18)\n",
    "    if n == 0:\n",
    "        ax[n].set_ylabel('E_2a_gdp', fontsize = 18)\n",
    "    ax[n].set_xlabel(metric, fontsize = 18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "states['E_2a_gdp_log'] = np.log(states['E_2a_gdp'])\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (24, 4), sharey = True)\n",
    "for n, num in enumerate(final_goals):\n",
    "    sns.scatterplot(data = states, y = 'E_2a_gdp_log', x = '%d %s' %(num, metric), ax = ax[n])\n",
    "    corr, p = stats.pearsonr(states['E_2a_gdp_log'], states['%d %s' %(num, metric)])\n",
    "    ax[n].set_title(\"%s\\n%0.2f %0.2f\" %(primary_goal_shorthand[sustainability[reference_text][num]], corr, p), fontsize = 18)\n",
    "    if n == 0:\n",
    "        ax[n].set_ylabel('E_2a_gdp_log', fontsize = 18)\n",
    "    ax[n].set_xlabel(metric, fontsize = 18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "states['P_3c_giniCoefficient_log'] = np.log(states['P_3c_giniCoefficient'])\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (24, 4), sharey = True)\n",
    "for n, num in enumerate(final_goals):\n",
    "    sns.scatterplot(data = states, y = 'P_3c_giniCoefficient_log', x = '%d %s' %(num, metric), ax = ax[n])\n",
    "    corr, p = stats.pearsonr(states['P_3c_giniCoefficient_log'], states['%d %s' %(num, metric)])\n",
    "    ax[n].set_title(\"%s\\n%0.2f %0.2f\" %(primary_goal_shorthand[sustainability[reference_text][num]], corr, p), fontsize = 18)\n",
    "    if n == 0:\n",
    "        ax[n].set_ylabel('P_3c_giniCoefficient_log', fontsize = 18)\n",
    "    ax[n].set_xlabel(metric, fontsize = 18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (24, 4), sharey = True)\n",
    "for n, num in enumerate(final_goals):\n",
    "    sns.scatterplot(data = states, y = 'population_2019_log', x = '%d %s' %(num, metric), ax = ax[n])\n",
    "    corr, p = stats.pearsonr(states['population_2019_log'], states['%d %s' %(num, metric)])\n",
    "    ax[n].set_title(\"%s\\n%0.2f %0.2f\" %(primary_goal_shorthand[sustainability[reference_text][num]], corr, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = states, x = 'E_2a_gdp', y = 'total reviews_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-output",
   "metadata": {},
   "source": [
    "## Predicting GDP, Gini, and Creativity\n",
    "\n",
    "- controls: urban population\n",
    "- dvs: gdp, gini, creativity (all logged and scaled)\n",
    "- 5 types of models for each:\n",
    "    - control only\n",
    "    - control + composite sustainability var [FAIR]\n",
    "    - control + all sustainability vars\n",
    "    - stepAIC(control + sustainability vars) ---> pick the best\n",
    "    - control + best from previous step [FAIR]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability_vars = ['%s' %(primary_goal_shorthand[sustainability[reference_text][i]]) for i in final_goals]\n",
    "new_names = dict([('%d %s' %(i, metric), '%s' %primary_goal_shorthand[sustainability[reference_text][i]]) for i in final_goals])\n",
    "states = states.rename(new_names, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the predictors (urban pop, composite score)\n",
    "\n",
    "# log every numerical column\n",
    "\n",
    "for col in states.columns:\n",
    "    if states[col].dtype in numerics:\n",
    "        states[col + '_log'] = np.log(states[col])\n",
    "\n",
    "\n",
    "var_list = ['S_9a_urbanPop_log', 'Openness_log', 'E_2a_gdp_log',\n",
    "            'Creativity Index ', 'H_2a_depression_num_log', 'composite']\n",
    "            #, 'rank-diff', 'PCA2']\n",
    "    # creativity is not skewed so no need to log it\n",
    "\n",
    "for var in var_list:\n",
    "    states[var + ' scaled'] = scale_var(states, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[[i + ' scaled' for i in var_list]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_regress(data, target, controls, composite, sustainable_vars, best):\n",
    "    # model 1\n",
    "    evs1 = controls\n",
    "    # model 2\n",
    "    evs2 = controls + composite\n",
    "    # model 3\n",
    "    evs3 = controls + sustainability_vars\n",
    "    # model 4\n",
    "    evs = controls + sustainability_vars\n",
    "    stepaic_vars, aic = stepaic_model(data, evs, target)\n",
    "    evs4 = list(set(list(stepaic_vars) + controls))\n",
    "    # model 5\n",
    "    evs5 = controls + best\n",
    "    \n",
    "    model1 = regress(data, evs1, target)\n",
    "    model2 = regress(data, evs2, target)\n",
    "    model3 = regress(data, evs3, target)\n",
    "    model4 = regress(data, evs4, target)\n",
    "    model5 = regress(data, evs5, target)\n",
    "    \n",
    "    #print(evs1, evs2, evs3, evs4)\n",
    "    return model1, model2, model3, model4, model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse inequlaity to equality\n",
    "\n",
    "# states['P_3c_giniCoefficient_log scaled'] = 1 - states['P_3c_giniCoefficient_log scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = 'E_2a_gdp_log scaled'\n",
    "gini = 'Openness_log scaled'\n",
    "creativity = 'Creativity Index  scaled'\n",
    "depression = 'H_2a_depression_num_log scaled'\n",
    "\n",
    "\n",
    "sustainability_score = 'composite scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to log or scale or scale for plots\n",
    "\n",
    "gdp_ = 'E_2a_gdp'\n",
    "gini_ = 'Openness'\n",
    "creativity_ = 'Creativity Index '\n",
    "depression_ = 'H_2a_depression_num'\n",
    "\n",
    "\n",
    "sustainability_score_ = 'composite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['S_9a_urbanPop', 'Openness', 'E_2a_gdp',\n",
    "            'Creativity Index ', 'H_2a_depression_num', 'composite']\n",
    "states[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(states['Creativity Index '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(states['composite'], states['Creativity Index _log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['S_9a_urbanPop_log scaled']\n",
    "null_gdp, composite_gdp, all_gdp, stepaic_gdp, best_gdp = multi_model_regress(states, gdp,\n",
    "                                                                    controls, [sustainability_score], \n",
    "                                                                    sustainability_vars,\n",
    "                                                                    best = [sustainability_score])\n",
    "Stargazer([null_gdp, composite_gdp, best_gdp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_gini, composite_gini, all_gini, stepaic_gini, best_gini = multi_model_regress(states, gini,\n",
    "                                                                    controls, [sustainability_score], \n",
    "                                                                    sustainability_vars,\n",
    "                                                                    best = [sustainability_score])\n",
    "Stargazer([null_gini, composite_gini, best_gini])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cc, composite_cc, all_cc, stepaic_cc, best_cc = multi_model_regress(states, creativity,\n",
    "                                                                    controls, [sustainability_score], \n",
    "                                                                    sustainability_vars,\n",
    "                                                                    best = [sustainability_score])\n",
    "Stargazer([null_cc, composite_cc, all_cc, stepaic_cc, best_cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_d, composite_d, all_d, stepaic_d, best_d = multi_model_regress(states, depression,\n",
    "                                                                    controls, [sustainability_score], \n",
    "                                                                    sustainability_vars,\n",
    "                                                                    best = [sustainability_score])\n",
    "Stargazer([null_d, composite_d, all_d, stepaic_d, best_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer([null_gdp, null_gini, null_cc, null_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer([composite_gdp, composite_gini, composite_cc, composite_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer([composite_gdp, best_gdp, composite_gini, best_gini, composite_cc, best_cc]).render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "def label_point(x, y, val, ax, adjust =  False, gap = .01):\n",
    "    texts = []\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        texts.append(ax.text(point['x']+gap, point['y'], str(point['val']), fontsize = 9))\n",
    "    if adjust:\n",
    "        adjust_text(texts, ax = ax)\n",
    "\n",
    "def sanity_plot(data, var_pairs, nrows, ncols, limit = 0, labeled = False):\n",
    "    if limit == 0:\n",
    "        limit = nrows * ncols\n",
    "    num = 0\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, figsize = (5*ncols, 5*nrows), sharey = True)\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            x, y = var_pairs[num]\n",
    "            sns.regplot(data = data, y = y, x = x, ax = axs[i][j])\n",
    "            corr, p = stats.pearsonr(data[y], data[x])\n",
    "            axs[i][j].set_title('R = %0.2f (p = %0.3f)' %(corr, p), fontsize = 16)\n",
    "            if labeled:\n",
    "                label_point(data[x], data[y],\n",
    "                        data['State Abbreviation'], axs[i][j])\n",
    "            num += 1\n",
    "            if num == limit:\n",
    "                break\n",
    "        if num == limit:\n",
    "            break\n",
    "    plt.tight_layout()\n",
    "    if labeled:\n",
    "        title = \"regressions/sanity_check_regressions_labeled.pdf\"\n",
    "    else:\n",
    "        title = \"regressions/sanity_check_regressions.pdf\"\n",
    "    #plt.savefig(PLOTROOT + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_plots(data, var_pairs, labeled = False):\n",
    "    fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 7), sharey = True)\n",
    "    for num in range(2):\n",
    "        x, x_name, y, y_name = var_pairs[num]\n",
    "        sns.regplot(data = data, y = y, x = x, ax = axs[num])\n",
    "        corr, p = stats.pearsonr(data[y], data[x])\n",
    "        axs[num].set_title('r = %0.2f (p = %0.3f)' %(corr, p), fontsize = 16)\n",
    "        #if num == 0:\n",
    "        axs[num].set_ylabel(y_name)\n",
    "#         else:\n",
    "#             axs[num].set_ylabel('')\n",
    "        axs[num].set_xlabel(x_name)\n",
    "        if labeled:\n",
    "            label_point(data[x], data[y], data['State Abbreviation'], axs[num], adjust = True)\n",
    "    plt.tight_layout()\n",
    "    if labeled:\n",
    "        title = \"%s_regressions_labeled.pdf\" %y\n",
    "    else:\n",
    "        title = \"%s_regressions.pdf\" %y\n",
    "    #plt.savefig(PLOTROOT + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_col_triplet_plots(data, var_pairs, labeled = False, ncols = 2, nrows = 2):\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, figsize = (5*ncols, 5*nrows), sharey = 'row')\n",
    "    num = 0\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            x, x_name, y, y_name = var_pairs[num]\n",
    "            corr, p = stats.pearsonr(data[y], data[x])\n",
    "            if p > 0.05:\n",
    "                sns.regplot(data = data, y = y, x = x, ax = axs[row][col], color = 'grey')\n",
    "            else:\n",
    "                sns.regplot(data = data, y = y, x = x, ax = axs[row][col])\n",
    "            axs[row][col].set_title('r = %0.2f (p = %0.3f)' %(corr, p), fontsize = 16)\n",
    "            #if col == 0:\n",
    "            axs[row][col].set_ylabel(y_name)\n",
    "            #else:\n",
    "            #    axs[row][col].set_ylabel('')\n",
    "            axs[row][col].set_xlabel(x_name)\n",
    "            if labeled:\n",
    "                label_point(data[x], data[y], data['State Abbreviation'], axs[row][col], adjust = True)\n",
    "            num += 1\n",
    "            \n",
    "            \n",
    "    if labeled:\n",
    "        title = \"wealth_inequality_cc_emergent_regressions_labeled_triplet.pdf\"\n",
    "    else:\n",
    "        title = \"wealth_inequality_cc_emergent_regressions_triplet.pdf\"\n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTROOT + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "states['H_2a_depression_num'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-posting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_pairs = [(sustainability_score_, \"composite\", gdp_, \"wealth\"),\n",
    "             (\"physiological\", \"physiological ODI\", gdp_, \"wealth\"),\n",
    "             (\"psychological\", \"psychological ODI\", gdp_, \"wealth\"),\n",
    "             (sustainability_score_, \"composite\", gini_, \"equality\"),\n",
    "             (\"physiological\", \"physiological ODI\", gini_, \"equality\"),\n",
    "             (\"psychological\", \"psychological ODI\", gini_, \"equality\"),\n",
    "             (sustainability_score_, \"composite\", creativity_, \"creativity\"),\n",
    "             (\"physiological\", \"physiological ODI\", creativity_, \"creativity\"),\n",
    "             (\"psychological\", \"psychological ODI\", creativity_, \"creativity\"),\n",
    "             (sustainability_score_, \"composite\", 'H_2a_depression_num', \"depression\"),\n",
    "             (\"physiological\", \"physiological ODI\", 'H_2a_depression_num', \"depression\"),\n",
    "             (\"psychological\", \"psychological ODI\", 'H_2a_depression_num', \"depression\"),\n",
    "            ]\n",
    "row_col_triplet_plots(states, var_pairs, ncols = 3, nrows = 4, \n",
    "                     # labeled = True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_row_plots(data, var_pairs, labeled = False, ncols = 4, nrows = 1):\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, figsize = (5*ncols, 5*nrows), sharey = False)\n",
    "    num = 0\n",
    "    for col in range(ncols):\n",
    "        x, x_name, y, y_name = var_pairs[num]\n",
    "        corr, p = stats.pearsonr(data[y], data[x])\n",
    "        if p > 0.05:\n",
    "            sns.regplot(data = data, y = y, x = x, ax = axs[col], color = 'grey')\n",
    "        else:\n",
    "            sns.regplot(data = data, y = y, x = x, ax = axs[col])\n",
    "        axs[col].set_title('R = %0.2f (p = %0.3f)' %(corr, p), fontsize = 22)\n",
    "        #if col == 0:\n",
    "        if col == 3:\n",
    "            num_is = \"iv\"\n",
    "        else:\n",
    "            num_is = \"i\" * (col+1)\n",
    "        axs[col].set_ylabel(\"%s) %s\" %(num_is, y_name), fontsize = 22)\n",
    "        axs[col].set_xlabel(x_name)\n",
    "        if labeled:\n",
    "            label_point(data[x], data[y], data['State Abbreviation'], axs[col], adjust = True)\n",
    "        num += 1\n",
    "            \n",
    "            \n",
    "    if labeled:\n",
    "        title = \"depression_wealth_cc_openness_regressions_labeled.pdf\"\n",
    "    else:\n",
    "        title = \"depression_wealth_cc_openness_regressions_labeled.pdf\"\n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTROOT + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_large_tick_values(tick_val, pos):\n",
    "    \"\"\"\n",
    "    Turns large tick values (in the billions, millions and thousands) such as 4500 into 4.5K and also appropriately turns 4000 into 4K (no zero after the decimal).\n",
    "    \"\"\"\n",
    "    if tick_val >= 1000000000:\n",
    "        val = round(tick_val/1000000000, 1)\n",
    "        new_tick_format = '{:}B'.format(val)\n",
    "    elif tick_val >= 1000000:\n",
    "        val = round(tick_val/1000000, 1)\n",
    "        new_tick_format = '{:}M'.format(val)\n",
    "    elif tick_val >= 1000:\n",
    "        val = round(tick_val/1000, 1)\n",
    "        new_tick_format = '{:}K'.format(val)\n",
    "    elif tick_val < 1000:\n",
    "        new_tick_format = round(tick_val, 1)\n",
    "    else:\n",
    "        new_tick_format = tick_val\n",
    "\n",
    "    # make new_tick_format into a string value\n",
    "    new_tick_format = str(new_tick_format)\n",
    "    \n",
    "    # code below will keep 4.5M as is but change values such as 4.0M to 4M since that zero after the decimal isn't needed\n",
    "    index_of_decimal = new_tick_format.find(\".\")\n",
    "    \n",
    "    if index_of_decimal != -1:\n",
    "        value_after_decimal = new_tick_format[index_of_decimal+1]\n",
    "        if value_after_decimal == \"0\":\n",
    "            # remove the 0 after the decimal point since it's not needed\n",
    "            new_tick_format = new_tick_format[0:index_of_decimal] + new_tick_format[index_of_decimal+2:]\n",
    "            \n",
    "    return new_tick_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_plots(data, var_pairs, labeled = False, ncols = 4, nrows = 1):\n",
    "    import matplotlib.ticker as tkr\n",
    "\n",
    "    formatter = tkr.ScalarFormatter(useMathText=True)\n",
    "    formatter.set_scientific(True)\n",
    "        #formatter.set_powerlimits((-2, 2))\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (6, 4.5), sharey = False)\n",
    "    num = 0\n",
    "    for col in range(ncols):\n",
    "        x, x_name, y, y_name = var_pairs[num]\n",
    "        corr, p = stats.pearsonr(data[y], data[x])\n",
    "        if p > 0.05:\n",
    "            ax = sns.regplot(data = data, y = y, x = x, color = 'grey')\n",
    "        else:\n",
    "            ax = sns.regplot(data = data, y = y, x = x, ax = ax, line_kws={\"format\": formatter})\n",
    "        ax.set_title('R = %0.2f (p = %0.3f)' %(corr, p), fontsize = 24, fontweight = 'bold')\n",
    "        #if col == 0:\n",
    "        if col == 3:\n",
    "            num_is = \"iv\"\n",
    "        else:\n",
    "            num_is = \"i\" * (col+1)\n",
    "        ax.set_ylabel(y_name, fontsize = 24, fontweight = 'bold')\n",
    "        ax.set_xlabel(x_name, fontsize = 24, fontweight = 'bold')\n",
    "        ax.set_yticklabels(ax.get_yticks(), size = 16)\n",
    "        ax.set_xticklabels(ax.get_xticks(), size = 16)\n",
    "        ax.set_yticklabels(ax.get_yticks().astype(int))\n",
    "        ax.set_xticklabels(ax.get_xticks().astype(int))\n",
    "        extra = data[y].quantile(.01)\n",
    "        ax.set_ylim(min(data[y]) - extra, max(data[y]) + extra)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if labeled:\n",
    "            label_point(data[x], data[y], data['State Abbreviation'], ax, adjust = True)\n",
    "        num += 1\n",
    "        \n",
    "        title = y_name + \".pdf\"\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PLOTROOT + title)     \n",
    "        plt.cla()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-postage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_pairs = [(sustainability_score, \"ODI\", 'H_2a_depression_num', \"Depression\"),\n",
    "             (sustainability_score, \"ODI\", creativity_, \"Creativity\"),\n",
    "             (sustainability_score, \"ODI\", gini_, \"Openness\"),\n",
    "             (sustainability_score, \"ODI\", gdp_, \"Wealth\"),\n",
    "            ]\n",
    "single_plots(states, var_pairs, ncols = 4, nrows = 1, \n",
    "                     #labeled = True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "sustainability_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict wealth, inequality, creativity with PCA vars (PC1, PCA2, rank-diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_regress(data, target, controls, composite, independent_vars, best):\n",
    "    # model 1\n",
    "    evs1 = controls\n",
    "    # model 2\n",
    "    evs2 = controls + composite\n",
    "    # model 3\n",
    "    evs3 = controls + independent_vars\n",
    "    # model 4\n",
    "    evs = controls + independent_vars\n",
    "    stepaic_vars, aic = stepaic_model(data, evs, target)\n",
    "    #evs4 = list(set(list(stepaic_vars) + controls))\n",
    "    evs4 = list(stepaic_vars)\n",
    "    # model 5\n",
    "    evs5 = controls + best\n",
    "    \n",
    "    model1 = regress(data, evs1, target)\n",
    "    model2 = regress(data, evs2, target)\n",
    "    model3 = regress(data, evs3, target)\n",
    "    model4 = regress(data, evs4, target)\n",
    "    model5 = regress(data, evs5, target)\n",
    "    \n",
    "    #print(evs1, evs2, evs3, evs4)\n",
    "    return model1, model2, model3, model4, model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['S_9a_urbanPop_log scaled']\n",
    "\n",
    "if split:\n",
    "    independent_vars = ['physiological', 'psychological']\n",
    "    states['physiological x psychological'] = states['physiological'] * states['psychological']\n",
    "    interactions = ['physiological x psychological']\n",
    "else:\n",
    "    independent_vars = ['composite']\n",
    "    interactions = []\n",
    "    \n",
    "# if True:\n",
    "#     independent_vars = ['composite']\n",
    "#     interactions = []\n",
    "\n",
    "# scale the indepenedent variables\n",
    "\n",
    "for var in independent_vars:\n",
    "    states[var] = scale_var(states, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add interactions if needed\n",
    "for var in independent_vars:\n",
    "    states['%s x urban' %var] = states[var] * states['S_9a_urbanPop_log scaled']\n",
    "    interactions.append('%s x urban' %var)\n",
    "    \n",
    "for var in interactions:\n",
    "    states[var] = scale_var(states, var)    \n",
    "    \n",
    "# add some interactions\n",
    "if interact:\n",
    "    independent_vars = independent_vars + interactions\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact, independent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_gdp, composite_gdp, all_gdp, stepaic_gdp, best_gdp = multi_model_regress(states, gdp,\n",
    "                                                                    controls, independent_vars, \n",
    "                                                                    independent_vars,\n",
    "                                                                    best = independent_vars)\n",
    "\n",
    "null_gini, composite_gini, all_gini, stepaic_gini, best_gini = multi_model_regress(states, gini,\n",
    "                                                                    controls, independent_vars, \n",
    "                                                                    independent_vars,\n",
    "                                                                    best = independent_vars)\n",
    "\n",
    "null_cc, composite_cc, all_cc, stepaic_cc, best_cc = multi_model_regress(states, creativity,\n",
    "                                                                    controls, independent_vars, \n",
    "                                                                    independent_vars,\n",
    "                                                                    best = independent_vars)\n",
    "\n",
    "null_d, composite_d, all_d, stepaic_d, best_d = multi_model_regress(states, depression,\n",
    "                                                                    controls, independent_vars, \n",
    "                                                                    independent_vars,\n",
    "                                                                    best = independent_vars)\n",
    "\n",
    "\n",
    "Stargazer([composite_gdp, stepaic_gdp, composite_gini, stepaic_gini, composite_cc, stepaic_cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stargazer([composite_gdp, best_gdp, composite_gini, best_gini, composite_cc, best_cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in paper, Table 5\n",
    "Stargazer([stepaic_d, stepaic_gdp, stepaic_cc, stepaic_gini])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-painting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(Stargazer([stepaic_d, stepaic_gdp, stepaic_cc, stepaic_gini]).render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in paper, Table 5\n",
    "Stargazer([all_d, all_gdp, all_cc, all_gini])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stargazer([all_d, all_gdp, all_cc, all_gini]).render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in paper, Table 5\n",
    "Stargazer([null_d, null_gdp, null_cc, null_gini])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-parcel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(states.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "states['ODI'] = states['composite']\n",
    "states['Urban Population'] = states['S_9a_urbanPop']\n",
    "states['Depression'] = states['H_2a_depression_num']\n",
    "states['Wealth'] = states['E_2a_gdp']\n",
    "states['Creativity'] = states['Creativity Index ']\n",
    "\n",
    "for var in ['Openness',\n",
    "                                                               'Extraversion',\n",
    "                                                               'Agreebleness',\n",
    "                                                               'Conscientiousness',\n",
    "                                                               'Neuroticism']:\n",
    "    states['%s' %str.upper(var[0])] = states[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-flooring",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_corr_vars = ['ODI',\n",
    "                   'Urban Population'] + ['Depression',\n",
    "                                          'Wealth',\n",
    "                                          'Creativity'] + ['O', 'C', 'E', 'A', 'N']\n",
    "                                                               \n",
    "                                    \n",
    "\n",
    "rows = []\n",
    "for i in range(0, len(cross_corr_vars)):\n",
    "    var1 = cross_corr_vars[i]\n",
    "    row = []\n",
    "    for j in range(0, i+1):\n",
    "        var2 = cross_corr_vars[j]\n",
    "        corr, p = stats.pearsonr(states[var1], states[var2])\n",
    "        if var1 == var2:\n",
    "            row.append(\"---\")\n",
    "            continue\n",
    "        if p < 0.005:\n",
    "            stars = \"***\"\n",
    "        elif p < 0.01:\n",
    "            stars = \"**\"\n",
    "        elif p < 0.05:\n",
    "            stars = \"*\"\n",
    "        else:\n",
    "            stars = \"\"\n",
    "        row.append(str(\"%0.3f\" %corr)+stars)\n",
    "    rows.append(row)\n",
    "    \n",
    "cross_corr = pd.DataFrame(rows, columns = cross_corr_vars)    \n",
    "cross_corr[\"var\"] = cross_corr_vars\n",
    "cross_corr = cross_corr.set_index(\"var\")\n",
    "cross_corr = cross_corr.fillna(\" \")\n",
    "cross_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_corr.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-behalf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-consensus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-paris",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-illinois",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[['Depressed mood',\n",
    " 'Sleep alterations',\n",
    " 'Fatigue/Loss of energy',\n",
    " 'Feelings of worthlessness',\n",
    " 'composite']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_stocks[['1 avg sim score',\n",
    " '2 avg sim score',\n",
    " '3 avg sim score',\n",
    " '5 avg sim score',\n",
    " 'composite']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-employee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var in cross_corr_vars:\n",
    "    print(var)\n",
    "    ax = sns.distplot(states[var], kde = False, color ='black', hist_kws=dict(alpha=1))\n",
    "    plt.axis('off')\n",
    "    #plt.show()\n",
    "    plt.savefig(PLOTROOT + \"distplots/%s.png\" %var)\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[cross_corr_vars].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "states[cross_corr_vars].describe().T[['min', 'max', '50%', 'mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states[cross_corr_vars].describe().T[['min', 'max', '50%', 'mean', 'std']].round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "states['composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-block",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
